{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Tugas Akhir Big Data.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "[Google Colab](https://colab.research.google.com/drive/1FfHOLLED_uv7T8RDfz602XWOSI1S1NCX?usp=sharing)"
      ],
      "metadata": {
        "id": "W6DSmVtQurfl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyspark\n",
        "!pip install sparknlp"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iqX52csIkaxH",
        "outputId": "b0f3c7d2-55a4-4489-d349-cd2387af97a3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyspark\n",
            "  Downloading pyspark-3.2.1.tar.gz (281.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 281.4 MB 37 kB/s \n",
            "\u001b[?25hCollecting py4j==0.10.9.3\n",
            "  Downloading py4j-0.10.9.3-py2.py3-none-any.whl (198 kB)\n",
            "\u001b[K     |████████████████████████████████| 198 kB 49.8 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.2.1-py2.py3-none-any.whl size=281853642 sha256=fd425dbc462d6c7fe9189c93b6f8f71d7bf05f134049657cee79f4d92d767175\n",
            "  Stored in directory: /root/.cache/pip/wheels/9f/f5/07/7cd8017084dce4e93e84e92efd1e1d5334db05f2e83bcef74f\n",
            "Successfully built pyspark\n",
            "Installing collected packages: py4j, pyspark\n",
            "Successfully installed py4j-0.10.9.3 pyspark-3.2.1\n",
            "Collecting sparknlp\n",
            "  Downloading sparknlp-1.0.0-py3-none-any.whl (1.4 kB)\n",
            "Collecting spark-nlp\n",
            "  Downloading spark_nlp-3.4.2-py2.py3-none-any.whl (142 kB)\n",
            "\u001b[K     |████████████████████████████████| 142 kB 23.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from sparknlp) (1.21.5)\n",
            "Installing collected packages: spark-nlp, sparknlp\n",
            "Successfully installed spark-nlp-3.4.2 sparknlp-1.0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install java\n",
        "import os\n",
        "! apt-get update -qq\n",
        "! apt-get install -y openjdk-8-jdk-headless -qq > /dev/null\n",
        "\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"PATH\"] = os.environ[\"JAVA_HOME\"] + \"/bin:\" + os.environ[\"PATH\"]\n",
        "! java -version"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x_JUkJUxRA9u",
        "outputId": "23c55296-4935-4eea-9899-ff20ead702d5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "openjdk version \"1.8.0_312\"\n",
            "OpenJDK Runtime Environment (build 1.8.0_312-8u312-b07-0ubuntu1~18.04-b07)\n",
            "OpenJDK 64-Bit Server VM (build 25.312-b07, mixed mode)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sparknlp\n",
        "spark = sparknlp.start() \n",
        "# sparknlp.start(gpu=True) >> for training on GPU\n",
        "from sparknlp.base import *\n",
        "from sparknlp.annotator import *\n",
        "from pyspark.ml import Pipeline\n",
        "from sparknlp.common import *\n",
        "import pandas as pd\n",
        "from pyspark.sql.functions import *\n",
        "print(\"Spark NLP version\", sparknlp.version())\n",
        "print(\"Apache Spark version:\", spark.version)"
      ],
      "metadata": {
        "id": "xJQ0g_qNh175",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "73bb275d-19d1-4051-c41d-bf85da2666e1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Spark NLP version 3.4.2\n",
            "Apache Spark version: 3.2.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = spark.read.option(\"header\",True).csv(\"mtsample_report.csv\")\n",
        "df = df.drop(\"_c0\")\n",
        "df.show(5)"
      ],
      "metadata": {
        "id": "5D0KUY1NlRho",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2abc2add-d450-4757-e208-434a66b894c7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+\n",
            "|      medical report|\n",
            "+--------------------+\n",
            "|\"CHIEF COMPLAINT:...|\n",
            "|\"HISTORY OF PRESE...|\n",
            "|HISTORY OF PRESEN...|\n",
            "|CHIEF COMPLAINT: ...|\n",
            "|REASON FOR CONSUL...|\n",
            "+--------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.withColumn('medical report', lower(col('medical report')))\n",
        "df = df.withColumn('medical report', regexp_replace('medical report','[^ ^a-z^0-9^,^.]',' '))\n",
        "df = df.withColumn('medical report', regexp_replace('medical report','\\.','. '))\n",
        "df.take(1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EnNQI_J3K_UP",
        "outputId": "1004182f-7f59-4172-e6ac-d068653538c1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Row(medical report=' chief complaint  abdominal pain. history of present illness  the patient is a 71 year old female patient of dr.  x.  the patient presented to the emergency room last evening with approximately 7  to 8 day history of abdominal pain which has been persistent.  she was seen 3 to 4 days ago at abc er and underwent evaluation and discharged and had a ct scan at that time and she was told it was   normal.    she was given oral antibiotics of cipro and flagyl.  she has had no nausea and vomiting but has had persistent associated anorexia.  she is passing flatus but had some obstipation symptoms with the last bowel movement two days ago.  she denies any bright red blood per rectum and no history of recent melena.  her last colonoscopy was approximately 5 years ago with dr.  y.  she has had no definite fevers or chills and no history of jaundice.  the patient denies any significant recent weight loss. past medical history  significant for history of atrial fibrillation under good control and now in normal sinus rhythm and on metoprolol and also on premarin hormone replacement. past surgical history  significant for cholecystectomy appendectomy and hysterectomy.  she has a long history of known grade 4 bladder prolapse and she has been seen in the past by dr.  chip winkel i believe that he has not been re consulted. allergies  she is allergic or sensitive to macrodantin. social history  she does not drink or smoke. review of systems  otherwise negative for any recent febrile illnesses chest pains or shortness of breath. physical examination general  the patient is an elderly thin white female very pleasant in no acute distress. vital signs  her temperature is 98. 8 and vital signs are all stable within normal limits. heent  head is grossly atraumatic and normocephalic.  sclerae are anicteric.  the conjunctivae are non injected. neck  supple. chest  clear. heart  regular rate and rhythm. abdomen  generally nondistended and soft.  she is focally tender in the left lower quadrant to deep palpation with a palpable fullness or mass and focally tender but no rebound tenderness.  there is no cva or flank tenderness although some very minimal left flank tenderness. pelvic  currently deferred but has history of grade 4 urinary bladder prolapse. extremities  grossly and neurovascularly intact. laboratory values  white blood cell count is 5. 3 hemoglobin 12. 8 and platelet count normal.  alkaline phosphatase elevated at 184.  liver function tests otherwise normal.  electrolytes normal.  glucose 134 bun 4 and creatinine 0. 7. diagnostic studies  ekg shows normal sinus rhythm. impression and plan  a 71 year old female with greater than one week history of abdominal pain now more localized to the left lower quadrant.  currently is a nonacute abdomen.  the working diagnosis would be sigmoid diverticulitis.  she does have a history in the distant past of sigmoid diverticulitis.  i would recommend a repeat stat ct scan of the abdomen and pelvis and keep the patient nothing by mouth.  the patient was seen 5 years ago by dr.  y in colorectal surgery.  we will consult her also for evaluation.  the patient will need repeat colonoscopy in the near future and be kept nothing by mouth now empirically.  the case was discussed with the patient s primary care physician dr.  x.  again currently there is no indication for acute surgical intervention on today s date although the patient will need close observation and further diagnostic workup.  ')]"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "document= DocumentAssembler()\\\n",
        ".setInputCol(\"medical report\")\\\n",
        ".setOutputCol(\"document\")\n",
        "\n",
        "sentence = SentenceDetector()\\\n",
        ".setInputCols([\"document\"])\\\n",
        ".setOutputCol(\"sentence\")\n",
        "\n",
        "token = Tokenizer()\\\n",
        ".setInputCols([\"sentence\"])\\\n",
        ".setOutputCol(\"token\")\n",
        "\n",
        "# stop_words = StopWordsCleaner.pretrained(\"stopwords_en\", \"en\") \\\n",
        "# .setInputCols([\"token\"]) \\\n",
        "# .setOutputCol(\"cleanTokens\")\\\n",
        "# .setCaseSensitive(False)\n",
        "\n",
        "# lemmatizer = LemmatizerModel.pretrained(\"lemma\",\"en\") \\\n",
        "# .setInputCols([\"token\"])\\\n",
        "# .setOutputCol(\"lemma\")\\\n",
        "# .setCaseSensitive(False)\n",
        "\n",
        "# finisher = Finisher() \\\n",
        "# .setInputCols([\"lemma\"])\\\n",
        "# .setOutputCols([\"token_features\"])\\\n",
        "# .setOutputAsArray(True) \\\n",
        "# .setCleanAnnotations(False)\n",
        "\n",
        "finisher = Finisher() \\\n",
        ".setInputCols([\"token\"])\\\n",
        ".setOutputCols([\"token_features\"])\\\n",
        ".setOutputAsArray(True) \\\n",
        ".setCleanAnnotations(False)"
      ],
      "metadata": {
        "id": "lblub95jaxEF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.feature import HashingTF, IDF, StringIndexer, IndexToString\n",
        "hashTF = HashingTF(inputCol = \"token_features\", outputCol = \"raw_features\")\n",
        "idf = IDF(inputCol = \"raw_features\", outputCol = \"features\")"
      ],
      "metadata": {
        "id": "6CXAth9x7bns"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nlpPipeline = Pipeline(stages=[\n",
        " document, \n",
        " sentence,\n",
        " token,\n",
        " finisher,\n",
        " hashTF,\n",
        " idf\n",
        " ])\n",
        "\n",
        "empty_df = spark.createDataFrame([['']]).toDF(\"medical report\")\n",
        "\n",
        "pipelineModel = nlpPipeline.fit(empty_df)"
      ],
      "metadata": {
        "id": "FWv4EWw8i-4G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result = pipelineModel.transform(df)\n",
        "result.show(truncate=20)"
      ],
      "metadata": {
        "id": "GPDbZAE4aq8H",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2bf8005d-9c05-413c-ae3b-152961f11fcc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
            "|      medical report|            document|            sentence|               token|      token_features|        raw_features|            features|\n",
            "+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
            "| chief complaint ...|[{document, 0, 34...|[{document, 1, 32...|[{token, 1, 5, ch...|[chief, complaint...|(262144,[2611,293...|(262144,[2611,293...|\n",
            "| history of prese...|[{document, 0, 24...|[{document, 1, 18...|[{token, 1, 7, hi...|[history, of, pre...|(262144,[161,1365...|(262144,[161,1365...|\n",
            "|history of presen...|[{document, 0, 20...|[{document, 0, 91...|[{token, 0, 6, hi...|[history, of, pre...|(262144,[9413,114...|(262144,[9413,114...|\n",
            "|chief complaint  ...|[{document, 0, 24...|[{document, 0, 23...|[{token, 0, 4, ch...|[chief, complaint...|(262144,[2325,236...|(262144,[2325,236...|\n",
            "|reason for consul...|[{document, 0, 19...|[{document, 0, 62...|[{token, 0, 5, re...|[reason, for, con...|(262144,[3336,538...|(262144,[3336,538...|\n",
            "|history of presen...|[{document, 0, 16...|[{document, 0, 17...|[{token, 0, 6, hi...|[history, of, pre...|(262144,[3336,376...|(262144,[3336,376...|\n",
            "|diagnosis  refrac...|[{document, 0, 37...|[{document, 0, 58...|[{token, 0, 8, di...|[diagnosis, refra...|(262144,[1546,304...|(262144,[1546,304...|\n",
            "|history of presen...|[{document, 0, 33...|[{document, 0, 18...|[{token, 0, 6, hi...|[history, of, pre...|(262144,[1415,154...|(262144,[1415,154...|\n",
            "|chief complaint  ...|[{document, 0, 19...|[{document, 0, 46...|[{token, 0, 4, ch...|[chief, complaint...|(262144,[1603,421...|(262144,[1603,421...|\n",
            "|reason for consul...|[{document, 0, 58...|[{document, 0, 96...|[{token, 0, 5, re...|[reason, for, con...|(262144,[521,1365...|(262144,[521,1365...|\n",
            "|reason for consul...|[{document, 0, 59...|[{document, 0, 10...|[{token, 0, 5, re...|[reason, for, con...|(262144,[4046,522...|(262144,[4046,522...|\n",
            "|reason for consul...|[{document, 0, 25...|[{document, 0, 35...|[{token, 0, 5, re...|[reason, for, con...|(262144,[161,1303...|(262144,[161,1303...|\n",
            "|subjective  the p...|[{document, 0, 49...|[{document, 0, 52...|[{token, 0, 9, su...|[subjective, the,...|(262144,[24,161,2...|(262144,[24,161,2...|\n",
            "|chief complaint  ...|[{document, 0, 29...|[{document, 0, 32...|[{token, 0, 4, ch...|[chief, complaint...|(262144,[3775,421...|(262144,[3775,421...|\n",
            "|chief complaint  ...|[{document, 0, 83...|[{document, 0, 31...|[{token, 0, 4, ch...|[chief, complaint...|(262144,[266,956,...|(262144,[266,956,...|\n",
            "|reason for hospit...|[{document, 0, 60...|[{document, 0, 86...|[{token, 0, 5, re...|[reason, for, hos...|(262144,[161,521,...|(262144,[161,521,...|\n",
            "|chief complaint  ...|[{document, 0, 16...|[{document, 0, 31...|[{token, 0, 4, ch...|[chief, complaint...|(262144,[1968,407...|(262144,[1968,407...|\n",
            "|chief complaint  ...|[{document, 0, 17...|[{document, 0, 32...|[{token, 0, 4, ch...|[chief, complaint...|(262144,[292,1934...|(262144,[292,1934...|\n",
            "|reason for consul...|[{document, 0, 35...|[{document, 0, 56...|[{token, 0, 5, re...|[reason, for, con...|(262144,[1303,256...|(262144,[1303,256...|\n",
            "|reason for follow...|[{document, 0, 27...|[{document, 0, 25...|[{token, 0, 5, re...|[reason, for, fol...|(262144,[161,1097...|(262144,[161,1097...|\n",
            "+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vectorized_tokens = lda_model.transform(result.select('token_features'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 310
        },
        "id": "c8TwrjCGqs3b",
        "outputId": "3144a819-9248-4b4c-d7d0-184d28d51eb6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IllegalArgumentException",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIllegalArgumentException\u001b[0m                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-d89f89786651>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mvectorized_tokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlda_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'token_features'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pyspark/ml/base.py\u001b[0m in \u001b[0;36mtransform\u001b[0;34m(self, dataset, params)\u001b[0m\n\u001b[1;32m    215\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    218\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Params must be a param map but got %s.\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pyspark/ml/wrapper.py\u001b[0m in \u001b[0;36m_transform\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m    348\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    349\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_transfer_params_to_java\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 350\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_java_obj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msql_ctx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    351\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    352\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1320\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1321\u001b[0m         return_value = get_return_value(\n\u001b[0;32m-> 1322\u001b[0;31m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[0m\u001b[1;32m   1323\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1324\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtemp_arg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtemp_args\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    115\u001b[0m                 \u001b[0;31m# Hide where the exception came from that shows a non-Pythonic\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m                 \u001b[0;31m# JVM exception message.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mconverted\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m                 \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIllegalArgumentException\u001b[0m: features does not exist. Available: token_features"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "lqxBRcSIq0Y4"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}